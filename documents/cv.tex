\documentclass[12pt]{article}

\usepackage{graphicx}
\graphicspath{{figs/}}

\usepackage{color}
\newcommand{\comment}[1]{{\color{red} [#1]}}

\newcommand{\given}{\,|\,}
\newcommand{\setof}[1]{\left\{{#1}\right\}}
\newcommand{\train}{\mathrm{train}}
\newcommand{\valid}{\mathrm{valid}}
\newcommand{\dd}{\mathrm{d}}

\newcommand{\Dtr}{\ensuremath{D^{\rm TR}}}
\newcommand{\Dva}{\ensuremath{D^{\rm V}}}
\newcommand{\Ntr}{\ensuremath{N^{\rm TR}}}
\newcommand{\Nva}{\ensuremath{N^{\rm V}}}

\newcommand{\eqn}[1]{eq.~(\ref{eq:#1})}
\newcommand{\fig}[1]{Fig.~\ref{fig:#1}}
\newcommand{\paper}{paper}

\title{Really Good Paper Title}
\author{}

\begin{document}
\maketitle

\begin{abstract}
  Bayesian confidence estimation and cross-validation are two possible
  approaches to the problem of statistical model selection.  The Bayesian
  approach has a sound basis in Bayesian probability theory, but is
  computationally difficult and highly sensitive to priors which may or may
  not be known.  The cross-validation approach is simpler to compute, but
  has a more heuristic basis.  In this \paper{} we show that there is an
  approximate quantitiative relationship between these two approaches to
  model selection, derive test statistics which evaluate when the
  computationally efficient cross-validation approach can be used in place
  of the difficulty-prone Bayesian approach.
\end{abstract}

%\section{Outline}
%\begin{itemize}
%\item Bayesianism is a solid approach, but the Bayes integral is hard \&
%  involves strong assumptions. {\bf Multi-dimensional integration
%    is generally expensive}
%\item CV is easy and has no -- or very few -- free parameters (we'll have to
%  think about how choice of CV scheme affects this)
%  {\bf Multi-dimensional optimization is generally cheaper}.
%\item Both approaches have {\it predictive power}, and for this reason we
%  should expect them to be related.
%\item Main subject of the paper: how can we determine {\it a priori} when the
%  two will give similar results?
%\item (Aside on LTFDFCF \& model selection?  Or leave for a future paper...)
%\end{itemize}

\section{Model Selection}
Model selection is the process of using data to decide between two models.
In general we'll distinguish between a model $M_1$ which has
parameters $\theta_{M1}$, and a model $M_2$ which has parameters $\theta_{M2}$.
The models can have multiple parameters:
$\theta_M$ is in general a vector or set of model parameters.
For example, imagine we would like to model the density of an observed
distribution of points in one dimension.  
$M_1$ might be a model in which our data is fit by a single
Gaussian: in this case the model parameters are $\theta_{M1} = \{\mu, \sigma\}$,
where $\mu$ is the mean of the distribution and $\sigma$ is the width of the
distribution.  $M_2$ might be a model in which our data is fit by two
Gaussians: in the model parameters are
$\theta_{M2} = \{\mu_1,\sigma_1,\mu_2,\sigma_2,w_{12}\}$ where $\mu_i,\sigma_i$
gives the mean and width of each Gaussian component, and $w_{12}$ gives the
relative weight of the two components. Notice that we have explicity
labeled the model parameters with the model name $M_1$ or $M_2$ as a reminder
that different models may have varying numbers of parameters.

Answering the question of which model best fits the data is a problem known
as {\it model selection}.  Two approaches are commonly used for this sort
of problem: the Bayesian approach of odds ratios and the frequentist approach
of cross-validation based on maximum likelihood.
\comment{should we mention AIC/BIC as well? Other cost functions?}
The frequentist approach is often the most simple: the cross-validation of
maximum likelihood is an optimization problem, which can be solved quickly
under most circumstances even in high-dimensional parameter spaces.
The Bayesian approach is in some sense the most rigorous: it allows for the
specific inclusion of prior information, and for the recovery of the full
posterior probability for each model.  This approach is not without its
weaknesses, however.  The Bayesian formalism is fundamentally a problem in
integration, and integration is much less efficient than optimization in
high dimensions.  Additionally, the Bayesian approach requires the
specification of a prior on the models: in cases where no actual prior
information exists, this specification becomes difficult, and even
so-called {\it uninformative priors} can have an effect on the final
result \comment{ref?}.

Nevertheless, both approaches are similar in that they can be shown to
have {\it predictive power}.  Because of this, we might expect them to
be related.  The goal of this work is to explicitly show the relationship
between the two methodologies, the assumptions used in relating the two,
and offer advice for deciding {\it a priori} when the faster frequentist
approach is a good approximation of the more rigorous but difficulty-laden
Bayesian approach.

\section{Frequentist Model Selection: Cross-Validation}
Cross-validation is a well-known approach in frequentism.  In the simplest
version of cross-validation, the data $D = \{d_n\}_{n=1}^N$
is divided into two samples:
the {\it training} data \Dtr{} used to train the model, and the
{\it validation} data \Dva{} which is used to validate the trained
model. It is important that these two samples are
non-overlapping and independent: in most cases this can be ensured by
allowing each observation to appear in just one of the sets\footnote{
 cross-validation of correlated observations are
 an interesting problem, but one we won't address in this paper
 \comment{ref?}.}.
To ensure independence, we will divide the data as follows: for $N$
observations we randomly choose \Ntr of the observations
as a training sample, and use the remaining $\Nva = N - \Ntr$
points as the validation set.
Without loss of generality we can re-order the data so that the
the training data is given by
\begin{equation}
  \Dtr = \{d_n\}_{n=1}^{\Ntr},
\end{equation}
and the validation data is given by
\begin{equation}
  \Dva = \{d_n\}_{n=\Ntr+1}^{N}.
\end{equation}

As mentioned above, cross-validation is a two-step process:
for each potential model $M$, the
training data \Dtr{} is used to construct the data likelihood as a function
of the vector of model parameters $\theta_M$.  This likelihood is of the form
\begin{equation}
  \label{eq:tr_likelihood}
  P(\Dtr|M, \theta_M, I) \propto \prod_{n=1}^{N^{\rm TR}}P(d_n|M, \theta_M, I).
\end{equation}
The terms $P(d_n|M, \theta_M, I)$ specify the probability of obtaining a
particular observation $d_n$ given our model described by $M$ and $\theta_M$:
this probability can be thought of as a limiting frequency of results within
some small range around the particular values $d_n$: thus this is a
``frequentist'' approach.
Maximizing the likelihood in with respect to the model parameters $\theta_M$
in \eqn{tr_likelihood} gives the {\it maximum likelihood estimate} (MLE)
of the model parameters, which we call
\begin{equation}
  \hat{\theta}_M^{max} \leftarrow \arg\max_{\theta_M} P(\Dtr|M, \theta_M, I).
\end{equation}
Based on this MLE, we compute the cross-validation score, which is the
cross-validation likelihood for the MLE parameter estimate:
\begin{equation}
  \label{eq:CV_likelihood}
  L_{CV}(M) = P(\Dva|M, \hat{\theta}_M^{max}, I)
\end{equation}
the model $M$ with the largest validation likelihood $L_{V}(M)$ is the
best-fit model chosen by the cross-validation procedure.

This approach can be very powerful, as well as computationally efficient.
However, by generalizing the notion of probability, we can approach this
from the Bayesian perspective, and gain further insight into the assumptions
made by the cross-validation approach.

\section{Bayesian Model Selection: the Odds Ratio}
The Bayesian approach is slightly different.  It seeks to compute the
{\it posterior model probability} $P(M|D,I)$, which by Bayes' theorem
can be expressed
\begin{equation}
  \label{eq:bayes_theorem}
  P(M|D,I) = \frac{P(D|M,I)P(M|I)}{P(D|I)}.
\end{equation}
The first term in the numerator is the {\it Bayes integral},\footnote{
Often, especially in the statistical literature,
the Bayes integral is confusingly called the {\it evidence}.}
as it is expressible as an integral over the likelihood used
in cross-validation (see below).
The second term in the numerator is known
as the {\it prior}, and encodes any prior knowledge constraining the model.
The term in the denominator is a normalization, and is usually not
computed explicitly.

The expression in \eqn{bayes_theorem} follows directly from the basic axioms
of probability, but note that
we have subtley changed the meaning of our terms here:
in the previous section, the probability
$P(\cdot)$ could be thought of as the limiting frequency of observed events.
Here, we consider the probabilities of {\it models}, which cannot be evaluated
in these frequentist terms.
Our former approach to probability is not applicable!

This underlies the fundamental difference between Bayesianism and frequentism:
in the Bayesian approach, we expand the definition of probability to include
probabilistic statements about our own knowledge.  When we write an expression
of the probability of a model given some data, $P(M|D)$, it quantifies the
extent of our knowledge about the model, or in general the particular
parameters within the model.

Bayesian model selection involves the comparison between two models $M_1$
and $M_2$ given their posterior probabilities.  It is convenient to express
this comparison in terms of the {\it odds ratio}, given by
\begin{equation}
  \label{eq:odds_ratio}
  O_{21} = \frac{P(M_2|D,I)}{P(M_1|D,I)}.
\end{equation}
The two model posteriors can be rewritten in terms of Bayes' rule using
\comment{XXX: ended here}
The nice thing here is that the denominator (which is hard to compute) cancels
leaving
\begin{equation}
  O_{21} = \frac{P(D|M_1,I)}{P(D|M_2,I)}\frac{P(M_1|I)}{P(M_2|I)}
\end{equation}
The first quotient is known as the {\it Bayes Factor}, and the second is the
ratio of the model priors.

Computing the odds ratio involves computation of the evidence $P(D|M,I)$
for each model.  This evidence is difficult to compute because it expresses
our degree of knowledge of the truch of model $M$ -- not for any
particular choice of model parameters,
but integrated over {\it all} possible combinations of parameters allowed
by the model.  We can express this integral explicitly in terms of the
likelihood used in the frequentist approach:
\begin{equation}
  \label{eq:evidence_integral}
  P(D|M, I) = \int \dd^{N_M}\theta_M P(D|M, I, \theta_M)P(\theta_M|M, I),
\end{equation}
where $N_M$ is the number of parameters in model $M$.

This integral illustrates the two practical difficulties of the Bayesian
approach: first, the prior term $P(\theta_M|M,I)$ must be specified, and
even so-called ``uninformative'' priors can affect the result, especially
in the case of model comparison.  Second, the integral must be computed
over all $N_M$ dimensions.
As the number of dimensions grows, the computational cost of this step
can become prohibitively expensive.

\section{Comparing Bayesianism and Frequentism}
Comparing the two approaches, we see that the likelihood plays a central
role in both Bayesian and frequentist model selection.  The difference
is that in frequentism we {\it optimize} the likelihood, while in
Bayesianism we {\it integrate} the likelihood.  The relationship between
these approaches can be seen as follows.

We'll start from the point of view of cross-validation.  The spirit of cross
validation is to maximize the likelihood of the validation data given the
training data.  In practice this is done through computing the cross-validation
likelihood using \eqn{CV_likelihood}.  In Bayesian terms, the quantity
approximated by the cross-validation likelihood can be expressed
\begin{equation}
  \label{eq:CV_likelihood_2}
  \widetilde{L}_{CV} = P(\Dva|\Dtr,M,I)
\end{equation}
Under what circumstances does $\widetilde{L}_{CV}$ in \eqn{CV_likelihood_2}
approximate ${L}_{CV}$ in \eqn{CV_likelihood}?  Via probability axioms,
we can re-express this quantity
\begin{eqnarray}
  \label{eq:LCV_derivation}
  \widetilde{L}_{CV} &=& P(\Dva|\Dtr,M,I)\nonumber\\
                    &=& \frac{P(\Dva, \Dtr|M,I)}{P(\Dtr|M,I)}\nonumber\\
                    &=& \frac{\int \dd\theta_M P(\Dva, \Dtr|\theta_M,M,I)
                                               P(\theta_M|M,I)}
                             {\int \dd\theta_M P(\Dtr, \theta|M,I)}\nonumber\\
                    &=& \frac{\int \dd\theta_M P(\Dva|\theta_M,M,I)
                                               P(\Dtr, \theta_M|M,I)}
                             {\int \dd\theta_M P(\Dtr, \theta_M|M,I)}.
\end{eqnarray}
The terms in the resulting integral are straightforward to understand:
\begin{description}
  \item[$P(\Dva|M, I, \theta_M)$] is the likelihood of the validation
    data.  In the cross-validation approach, this is maximized for $M$,
    for parameters $\theta_M = \hat{\theta}^{max}_M$ at their fixed, to choose
    the model $M$.
  \item[$P(\Dtr,\theta_M|M, I)$] is the joint probability of the training data
    and the model parameters.  This term contains the training likelihood used
    to fix  $\theta_M = \hat{\theta}^{max}_M$ in the first step of the cross
    validation.  The fact that it appears in both the top and bottom integrals
    becomes important below.
\end{description}

If we now make the approximation
\begin{equation}
  \label{eq:CV_approximation}
  P(\Dtr,\theta_M|M,I) \approx P(\Dtr|M, I)
                               \delta(\theta_M - \hat{\theta}^{\max}_M),
\end{equation}
the delta function collapses the integral, the remaining term cancels,
and we find $\widetilde{L}_{CV} \approx {L}_{CV}$.  This approximation
involves two related assumptions:
\begin{enumerate}
  \item The variables \Dtr{} and $\theta_M$ are approximately independent
    {\it on scales of interest}.
  \item The probability distribution $P(\theta_M|\Dtr, M, I)$ is very narrow
    {\it on scales of interest}.
\end{enumerate}
The scale of interest, as seen in the bottom line of \eqn{LCV_derivation},
is the scale over which the validation likelihood $P(\Dva|\theta_M, M, I)$
varies significantly: if the validation likelihood is very slowly changing,
then the MLE approximation holds and $\widetilde{L}_{CV} \approx {L}_{CV}$.
This approximation is visualized in \fig{approx_vis}.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{plot_collapse_1.pdf}
  \caption{A schematic visualization of the probability approximation used to
    relate cross-validation to the Bayesian formalism.  The left panel shows
    the true joint distribution between the training data \Dtr{} and the
    model parameters $\theta_M$.  The right panel shows the approximation
    given by \eqn{CV_approximation}.}
  \label{fig:approx_vis}
\end{figure}

Can we expect this approximation to be valid?  The answer depends on the
precise relationship between the model $M$, the training data \Dtr, and
the validation data \Dva{}.  In particular, if the size of the training set
is much larger than the size of the cross-validation set, and if the two
are consistent with being drawn from the same distribution, this approximation
will hold (see further discussion below).

In the regime where this approximation holds, we can use the derived
approximation to learn the relationship between the cross-validation
likelihood $L_{CV}$ and the odds ratio $O_{21}$ for two models.  From
\eqn{CV_approximation} we have:
\begin{eqnarray}
  \widetilde{L}_{CV} &=& P(\Dtr,\theta_M|M,I)\nonumber\\
                    &=& \frac{P(D|M, I)}{P(\Dtr|M, I)}
\end{eqnarray}
Using this result, the odds ratio given by \eqn{odds_ratio} can be expressed
\begin{equation}
  O_{21} = \frac{\widetilde{L}_{CV,2}}{\widetilde{L}_{CV,1}}
          \frac{P(\Dtr|M_2,I)}{P(\Dtr|M_1,I)}.
\end{equation}
The odds ratio is related to the approximate cross-validation likelihood,
multiplied by a data posterior.  Looking more closely, though, we see
an interesting result: the second quotient looks just like the odds
ratio computed from the {\it training data} only.  If we define
\begin{equation}
  O_{21}^{\rm TR} \equiv  \frac{P(\Dtr|M_2,I)}{P(\Dtr|M_1,I)},
\end{equation}
then the odds ratio can be expressed
\begin{equation}
  O_{21} = \frac{\widetilde{L}_{CV,2}}{\widetilde{L}_{CV,1}} O_{21}^{\rm TR}.
\end{equation}
This expression suggests an iterative approach to approximating the odds
ratio without computing a single integral over parameter space:
the odds ratio for the full data can be expressed as a product of the
cross-validation scores and the odds ratio for the training data. The
odds ratio for the training data in turn can be expressed in terms of
the cross-validation applied to a subset.  This procedure can be repeated,
as long as the approximation in \eqn{CV_approximation} holds.

Perhaps more importantly, this approach {\it removes the need to explicitly
choose the prior} which appears in \eqn{odds_ratio}.  This is a very valuable
trait, but comes at the cost of the approximation at each step.  Below we
will attempt to quantify the effect of this approximation in particular
situations, and explicitly compare the exact results with the approximations
in a variety of settings.

[think about some examples]

\section{Quantifying the Approximation}
In what situation can the frequentist approach be used as a substitute for
the Bayesian formulation?

\section{Examples}
We should come up with some good ones.

\section{Extension to Other CV Schemes}

We might be able to make the leap to $K$-fold cross-validation due to the fact
that adding a single training point to a set will (for well-behaved sets)
have a negligible effect on the total likelihood.

\begin{eqnarray}
p(D\given\theta,H) &=& \prod_{n=1}^N p(D_n\given\theta,H)
\\
D &\equiv& \setof{D_n}_{n=1}^N
\\
D^\train_k &\equiv& \setof{D_n}_{n\in\train(k)}
\\
D^\valid_k &\equiv& \setof{D_n}_{n\in\valid(k)}
\\
p(D^\train_k\given\theta,H) &=& \prod_{n\in\train(k)} p(D_n\given\theta,H)
\\
p(D^\valid_k\given\theta,H) &=& \prod_{n\in\valid(k)} p(D_n\given\theta,H)
\\
p(\theta\given D^\train_k,H) &=& \frac{1}{Z_{Hk}}\,p(D^\train_k\given\theta,H)\,p(\theta\given H)
\\
Z_{Hk} &\equiv& \int p(D^\train_k\given\theta,H)\,p(\theta\given H)\,\dd\theta
\\
\theta_k &\leftarrow& \arg\max_\theta p(D^\train_k\given\theta,H)
\\
L_k &\equiv& p(D^\valid_k\given\theta_k,H)
\\
L &\equiv& \prod_{k=1}^K L_k
\\
\zeta_k &\equiv& \int p(D^\valid_k\given\theta,H)\,p(\theta\given D^\train_k,H)\,\dd\theta
\\
Z_H &\equiv& \int p(D\given\theta,H)\,p(\theta\given H)\,\dd\theta
\\
\zeta_k &=& \frac{Z_H}{Z_{Hk}}
\quad,
\end{eqnarray}

\end{document}
